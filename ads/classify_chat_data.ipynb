{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "import jieba\n",
    "import traceback\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "from itertools import chain\n",
    "from collections import defaultdict\n",
    "from multiprocessing import Pool\n",
    "# from multiprocessing import get_context\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 10**5)\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def apply_parallel(df, func, n=-1):\n",
    "    n = os.cpu_count() if -1 == n else n\n",
    "    \n",
    "    df_ = np.array_split(df, n)\n",
    "    with Pool(n) as p:\n",
    "    # with get_context('spawn').Pool(n) as p:\n",
    "        dfr = pd.concat(p.map(func, df_))\n",
    "        # r = p.map(func, df_)\n",
    "    p.join()\n",
    "    \n",
    "    # dfr = pd.Series(chain.from_iterable(r))\n",
    "    # print(df.shape, dfr.shape)\n",
    "    # print(dfr.head(100))\n",
    "    \n",
    "    return dfr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(path, filename):\n",
    "\n",
    "    df = pd.read_csv(os.path.join(path, filename), index_col=0)\n",
    "    # print(df.shape)\n",
    "    # df.head(1)\n",
    "\n",
    "    texts = df[['content']]\n",
    "    # print(texts.shape)\n",
    "    # texts.head(1)\n",
    "    \n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# texts = texts[texts.content == 'é«˜ä»·æ”¶å´å›½é«˜è¿å·ï¼Œæœ‰æ„çš„ç§èŠï¼Œæ™šä¸Šä¹ç‚¹ç»Ÿä¸€å›žå¤ï¼']\n",
    "# texts = texts[texts.content == 'æœ‰æ„è¯·åŠ VX18526109947']\n",
    "# texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chars"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "texts[texts.str.contains('^{[a-z]*:[0-9]+.*}$')].reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## localization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def filter_localization(texts):\n",
    "\n",
    "    texts = texts[~texts['content'].str.contains('^{localization:[0-9]+\\-[0-9]+}$')].reset_index(drop=True)\n",
    "    # print(texts.shape)\n",
    "    # texts.head(1)\n",
    "    \n",
    "    return texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## battle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_battle(texts):\n",
    "\n",
    "    texts = texts[~texts['content'].str.contains('^{battle:[0-9]+,ã€.*ã€‘.*}$')].reset_index(drop=True)\n",
    "    # texts.shape\n",
    "\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## system info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_system_info(texts):\n",
    "\n",
    "    texts = texts[~texts['content'].str.contains('^{[a-z]*:[0-9]+.*}$')].reset_index(drop=True)\n",
    "    # texts.shape\n",
    "\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# pd.DataFrame(texts.head(10))\n",
    "texts.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_lower(texts):\n",
    "\n",
    "    texts['tokens'] = texts['content'].str.strip().str.lower()\n",
    "    # print(len(texts))\n",
    "\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_special_words(texts):\n",
    "\n",
    "    sw = [r'\\s+', r'{localization:[0-9]+\\-[0-9]+}', 'ä¸¶']\n",
    "\n",
    "    for _ in sw:\n",
    "        texts['tokens'] = texts['tokens'].str.replace(_, '')\n",
    "        # print(len(texts))\n",
    "\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## meaningless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_numeric_only(texts):\n",
    "\n",
    "    texts = texts[~texts['tokens'].str.isnumeric()]\n",
    "    # print(len(texts))\n",
    "\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## merge chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_chars(texts):\n",
    "\n",
    "    dict_merge_chars = {'è´æˆ‹' : 'è´±', 'çŠ­å¥' : 'ç‹—', 'å¥³é©¬' : 'å¦ˆ'}\n",
    "\n",
    "    for k, v in dict_merge_chars.items():\n",
    "        texts['tokens'] = texts['tokens'].str.replace(k, v)\n",
    "\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tokenization"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def tokenize(df):\n",
    "    return df.apply(jieba.lcut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def tokenization(texts):\n",
    "\n",
    "    texts['tokens'] = texts['tokens'].apply(jieba.lcut)\n",
    "    # texts['tokens'] = apply_parallel(texts['tokens'], jieba.lcut)\n",
    "    # print(len(texts))\n",
    "    \n",
    "    # texts['tokens'] = apply_parallel(texts['tokens'], tokenize)\n",
    "\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "texts.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### chars + numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chars_numbers(i):\n",
    "    \"\"\" tool\n",
    "    \"\"\"\n",
    "    \n",
    "    m = re.match('^([a-z]+)([0-9]+)$', i)\n",
    "    if m: return list(m.groups())\n",
    "    \n",
    "    m = re.match('^([0-9]+)([a-z]+)$', i)\n",
    "    if m: return list(m.groups())\n",
    "    \n",
    "    return [i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_chars_numbers(x):\n",
    "    \"\"\" tool\n",
    "    \"\"\"\n",
    "    \n",
    "    return list(chain.from_iterable([chars_numbers(i) for i in x])) "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def batch_split_cn(df):\n",
    "    return df.apply(split_chars_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_cn(texts):\n",
    "\n",
    "    texts['tokens'] = texts['tokens'].apply(split_chars_numbers)\n",
    "    # print(len(texts))\n",
    "    # texts.head(1)\n",
    "    \n",
    "    # texts['tokens'] = apply_parallel(texts['tokens'], batch_split_cn)\n",
    "\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### special words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_split = {\n",
    "'å¤§é‡å‡º' : ['å¤§é‡', 'å‡º'],\n",
    "'åŠ å¾®ä¿¡' : ['åŠ ', 'å¾®ä¿¡'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_special_words(texts):\n",
    "\n",
    "    texts['tokens'] = texts['tokens'].apply(lambda x: list(chain.from_iterable([dict_split.get(i,[i]) for i in x])))\n",
    "    # print(len(texts))\n",
    "    # texts.head(1)\n",
    "\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## merge words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_merge2 = [['èµ„æº', 'å•†'], ['å¼ ', 'è¾½'], ['c', 'ä½'], ['éƒ¡', 'åŸŽ'], ['æ´—æ´—', 'ç¡'], ['å®ˆ', 'ä¸ä½'], ['åˆš', 'æœ‰äº‹'], ['å¼ƒ', 'å‘'], ['æ–°æ‰‹', 'æœ'], ['å¸¦', 'å…µ'], ['è€', 'æ ·å­'], \n",
    "               ['å†’ä¸ª', 'æ³¡'], ['ç™½', 'å«–'], ['äº²', 'å¯†åº¦'], ['æ‰“å¯‡', 'åŒª'], ['å‘¨å¹´', 'åº†'], ['å¸¦', 'èŠ‚å¥'], ['çŽ©', 'æ¸¸æˆ'], ['æ–°', 'ç‰ˆæœ¬'], ['ç§¯ç‚¹', 'å¾·'], ['ç‚¸', 'çŸ¿'], ['èµ›å­£', 'æœ'], \n",
    "               ['é‚º', 'åŸŽ'], ['æƒ³', 'åŠžæ³•'], ['ä¹Œ', 'éª“'], ['é¾Ÿ', 'å­™'], ['çº¢', 'æ‰‹æŒ‡'], ['æ­»', 'å¦ˆ'], ['2', 'é˜Ÿ'], ['ç­‰', 'ä¼š'], ['æ‰“', 'ä¸è¿‡'], ['å¥½', 'å§'], ['ç­‰', 'ä¸‹'], ['æ‰“', 'æŽ‰'], \n",
    "               ['åŽ»', 'å§'], ['ç­‰', 'ä¸€ä¸‹'], ['æ‰“', 'ä¸€ä¸‹'], ['æ‰“', 'å“ª'], ['æ”¶å…µ', 'çº¿'], ['æ’¤', 'å§'], ['ä¸', 'å®¢æ°”'], ['ç¨', 'ç­‰'], ['ä¸', 'æ‡‚'], ['æ‰“', 'ä¸äº†'], ['ä¸ä¼š', 'å§'],\n",
    "              ['ä¸', 'ç¨³å®š'], ['ä¸‹', 'ä¸€ä¸ª'], ['äºº', 'ä¸å¤Ÿ'], ['åŠªåŠ›', 'ä¸­'], ['èµŒ', 'ä¸€æŠŠ'], ['åˆ°', 'ç‚¹'], ['1', 'é˜Ÿ'], ['æ²¡çœ‹', 'æ‡‚'], ['+', '1'], ['åˆä¸ª', 'å½±'], ['ç‡•å­', 'åž'],\n",
    "              ['ä¸€', 'æ¢­å­']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_merge3 = [['é’å±±', 'ä¸æ”¹', 'ç»¿æ°´é•¿æµ'], ['æ‰“', 'ä¸', 'æ‰“'], ['æ¥', 'ä¸æ¥']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge3(x):\n",
    "    \"\"\" tool\n",
    "    \"\"\"\n",
    "    \n",
    "    if 2 > len(x): return x\n",
    "    \n",
    "    r = []\n",
    "    i = len(x) - 1\n",
    "    \n",
    "    while(1<i):\n",
    "        if [x[i-2],x[i-1],x[i]] in list_merge3:\n",
    "            r.insert(0, ''.join([x[i-2],x[i-1],x[i]]))\n",
    "            i -= 3\n",
    "        else:\n",
    "            r.insert(0, x[i])\n",
    "            i -= 1\n",
    "\n",
    "    if 1 == i:\n",
    "        r.insert(0, x[1])\n",
    "        r.insert(0, x[0])\n",
    "            \n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge2(x):\n",
    "    \"\"\" tool\n",
    "    \"\"\"\n",
    "    \n",
    "    if 2 > len(x): return x\n",
    "    \n",
    "    r = []\n",
    "    i = len(x) - 1\n",
    "    \n",
    "    while(0<i):\n",
    "        if [x[i-1],x[i]] in list_merge2:\n",
    "            r.insert(0, ''.join([x[i-1],x[i]]))\n",
    "            i -= 2\n",
    "        else:\n",
    "            r.insert(0, x[i])\n",
    "            i -= 1\n",
    "            \n",
    "    if 0 == i:\n",
    "        r.insert(0, x[0])\n",
    "            \n",
    "    return r"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def batch_merge_words_3(df):\n",
    "    return df.apply(merge3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def merge_words_3(texts):\n",
    "\n",
    "    texts['tokens'] = texts['tokens'].apply(merge3)\n",
    "    # print(len(texts))\n",
    "    # texts.head(1)\n",
    "    \n",
    "    # texts['tokens'] = apply_parallel(texts['tokens'], batch_merge_words_3)\n",
    "\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def batch_merge_words_2(df):\n",
    "    return df.apply(merge2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_words_2(texts):\n",
    "\n",
    "    texts['tokens'] = texts['tokens'].apply(merge2)\n",
    "    # print(len(texts))\n",
    "    # texts.head(1)\n",
    "    \n",
    "    # texts['tokens'] = apply_parallel(texts['tokens'], batch_merge_words_2)\n",
    "\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### regular"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def get_stopwords(path):\n",
    "    stopwords = []\n",
    "    for filename in os.listdir(path):\n",
    "        with open(os.path.join(path, filename), 'r') as f:\n",
    "            stopwords.extend([w.strip() for w in f.readlines()])            \n",
    "    return stopwords"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "stopwords = get_stopwords('/home/wangyh/project/document_cluster/dicts/')\n",
    "print(len(stopwords))\n",
    "stopwords[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ads detect only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw = ['â€¦', 'âŠ™', 'âˆ€', 'à²¡', 'Ï‰', 'à²¡', 'ðŸ˜‚', 'ðŸ˜œ', 'è°¢è°¢', 'å“ˆ', 'å“ˆå“ˆ', 'å“ˆå“ˆå“ˆ', 'å“ˆå“ˆå“ˆå“ˆ', 'æ˜Žå¤©', 'æ™šä¸Š', 'ä¸­åˆ', 'åˆ·', 'åˆ·åˆ·', 'éœ', 'å¼€', 'å¼€å¼€', 'å‡ ç‚¹', 'æ²¡', 'æ”¹', 'å†›å›¢',\n",
    "     'æ•£', 'ç»“æŸ', 'åˆ‡ç£‹', 'é˜Ÿä¼', 'æ—©', 'è¯´', 'æŒ‚å…', 'ä¸¢äºº', 'æ‰“åŒª', 'é©»é˜²', 'æ„Ÿè°¢', 'å†è§', 'æ¥åˆ·', 'æŠ±æ­‰', 'è¡Œå†›', 'é£ž', 'ç‰›', 'ç‰›ç‰›', 'åšäºº', 'å–„è‰¯', 'èµž', 'èµžèµž', 'èµžèµžèµž',\n",
    "     'å…„å¼Ÿ', 'é£Žäº‘', 'æ–‡æ˜Ž', 'é£žè¿‡æ¥', 'æ‹', 'å®Œ', 'æ‹‰', 'æ±‚è™', 'æ‰¾', 'æ¸£', 'å–Š', 'æ‹ç…§', 'è¯•è¯•', 'è°¢', 'æŠ¢', 'å‘', 'æ²¡äº‹', 'å–Š', 'å ', 'åš', 'è¯•', 'ä»Šæ™š', 'æ›´æ–°', 'ç¡è§‰', \n",
    "      'èµ°', 'å¸®å¿™', 'å¸®', 'ä¸€ä¼š', 'åƒ', 'â•¯', 'â•°', 'æºœ', 'å·', 'åˆ·ä¸åˆ·', 'â†', 'à²¥', 'åŠ é€Ÿ', 'æŽ¥', 'åš', 'è¿™æ˜¯', 'å‘±å”§', 'å…ˆæ‰“', 'åŽ¿åŸŽ', 'åŽ¿', 'æ‰“ä¸åŠ¨', 'ä¸ç”¨', 'å–é…’', 'ä¸å¥½æ„æ€',\n",
    "     'å”§å”§', 'æ²¡äº‹', 'é€Ÿåº¦', 'å…ˆ', 'æ´¾', 'å¼„', 'ç•™ä¸ª', 'çºªå¿µ', 'à¸‡', 'â€¢', 'Ì€', 'â€¢', 'Ì', 'æŠ¥å', 'æ–°', 'æ–°ç‰ˆæœ¬', 'è½®å­', 'å—²', 'å¥³é©¬', 'ä¸€æ¡', 'èˆ”', 'èŠèŠ±', 'å±è‚¡', 'ç§ƒé¡¶', 'åŽä»£', 'å…”å­', \n",
    "     'é¹°é…±', 'å…¨å®¶', 'å‘è´§', 'åˆç…§', 'æ¸¸æˆ', 'å¤ª', 'å›¢', 'é‡Œ', 'è¯…å’’', 'åˆå½±', 'ä¸€é˜Ÿ', 'äºŒé˜Ÿ', 'äºŒå›¢', 'ä¸‰å›¢', 'ä¸€ç¾¤ç¾¤', 'é˜¿çŒ«', 'éª—', 'åˆ ', 'ç»Ÿä¸€', 'ç­¾åˆ°', 'è‡ªåŠ¨', 'è€å­', 'è¯´è¯', \n",
    "      'çªå›ŠåºŸ', 'æ­»å¦ˆ', 'æ²¡å¦ˆ', 'çŸ­å‘½', 'æ¸£ç§', 'æˆå¤©', 'åªä¼š', 'äº²éº»', 'æ‰“æ³¡', 'äº²è·Œ', 'æ­»', 'å ', 'éª‚', 'èµ¢', 'æ±Ÿæ¹–', 'æ•…äºº', 'ç›¸é€¢', 'é’å±±', 'ä¸æ”¹', 'ç»¿æ°´é•¿æµ', 'ä¸‡äº‹', 'é¡ºé‚',\n",
    "     'å°”éš†', 'å’šé”µ', 'è¿›', 'å·®', 'è¿œ', 'åˆ', 'ï¼Œ', 'éƒ½', 'æ˜¯', 'å°±æ˜¯', 'çš„', 'æ›´å¥½', 'å‘å±•', 'åˆ©ç”¨', 'ï¼Œ', 'å¤§å®¶', 'ä¸€èµ·', 'ä½œæˆ˜', 'æœ‰', 'å’Œ', 'ä½ ', 'æˆ‘', 'è¿˜', 'åœ¨çº¿', 'ã€‚', '*', 'ã€', ':',\n",
    "     'æ‚¨', 'èƒ½', 'ä¸º', 'äº†', 'å°±', 'ï¼ˆ', 'ï¼Ÿ', 'å—', 'æ¥', 'äº†', 'èƒ½', 'ä¸èƒ½', 'å¤§', 'å˜›', 'è¢«', 'é‚£', 'åœ¨', 'ï¼', 'ä»–', 'å†', 'è‡ªå·±', 'åæ ‡', 'æˆªå›¾', 'ï¼', 'å‡†å¤‡', 'é€€åœº', '2é˜Ÿ', 'è¿™', \n",
    "     'ç§¯ç‚¹å¾·', 'ä¹Ÿ', 'è®©', 'ä»–ä»¬', 'å•Š', 'çŽ°åœ¨', 'ä¸ºäº†', 'ä½ å¥½', 'æ‚¨å¥½', 'æœ¬', 'æœ‰å¿—', 'é’å¹´', 'å…±åŒ', 'è¿ŽæŽ¥', 'ç›´æŽ¥', 'ç”³è¯·', 'èœ€å›½', 'åŠ æ²¹', 'ç ¸ç§', 'ç‹—', 'æ±—é—´', 'é­ä¸»', \n",
    "      'ç¥–å®—', 'çŽ°å®ž', 'åœ°ä½', 'ä¹è¶£', 'å‘¢', 'è®¤è¯†', 'æ‹¿', 'ä¸ª', 'æ¯”', 'å½“', 'ä»¬', 'ä¸€åœº', 'æŒä¹…æˆ˜', 'ç›¸ä¿¡', 'èƒœåˆ©', 'ç»ˆå°†', 'å±žäºŽ', 'æˆ‘ä»¬', 'å›¢ç»“', 'ä¸€å®š', 'èƒœåˆ©', 'æ¬¢è¿Ž', 'æ‰€æœ‰', \n",
    "      'å´å›½', 'å¤§è€', 'é»‘', 'åˆç§°', 'çœŸäºº', 'å¹¿å¤§', 'ç¾¤ä¼—', 'è¿œç¦»', 'äº²ç ', 'å—·å—·å«', 'å­é¡º', 'å„¿', 'æ‡†', 'å¾—', 'è¿™ä¸ª', 'å–”', 'çŒª', 'æ‹±', 'æµ‘èº«', 'æºƒçƒ‚', 'æ­£åœ¨', 'å–', 'è„“è¡€', 'ç–—ä¼¤',\n",
    "     'å¯æ€œ', 'å®¶é‡Œ', 'å¾—', 'å‰©', 'çŸ¥é“', 'ä¸', 'å®¹æ˜“', 'çˆ¶æ¯', 'ç­‰', 'ç€', 'æ‹¿', 'é’±', 'ä¹°', 'æ£ºæ', 'ä¸‹è‘¬', 'å‘¢', 'å¯æ˜¯', 'é‚£ç‚¹', 'çˆ¶æ¯', 'çƒ§çº¸', 'ä¸å¤Ÿ',\n",
    "      'ä¸', 'çŸ¥é“', 'å›ž', 'äº‘å¤©', 'é™ª', 'æ‰€è°“', 'â€œ', 'â€', 'è¿˜æ˜¯', 'åƒ', 'ç™žçš®ç‹—', 'ä¸€æ ·', 'ç»§ç»­', 'ç•™åœ¨', 'å¤§è…¿', 'å¯ä»¥', 'æŠ±', 'å›¢é‡Œ', 'å½“å¥´æ‰', 'æ‹­ç›®ä»¥å¾…',\n",
    "     'ç§åœ°', 'çŽ°å®ž', 'æ®‹é…·', 'å†œæ°‘', 'ä»¬', 'è¾›è‹¦', 'å•¦', 'ä¸è¾žè¾›è‹¦', 'åšæŒ', 'å¸½å­', 'å°', 'å†œæ°‘', 'æ€ç»´', 'çœŸæ˜¯', 'å•çº¯', 'å¯çˆ±', 'æƒ¹', 'äºº', 'ç–¼', 'å‘¢', 'ä¸', 'çŸ¥é“', 'ä¸', 'æ‰“', \n",
    "      'å®æœ', 'å‚»', 'ç¬”çŽ‹', 'äºº',  'å‘¢', 'æ‰“', 'å§', 'æ­¤', 'ä¸è‚–', 'å­', 'è¿˜æœ‰', 'äºº', 'é›†ç»“', 'ç•™å¿µ', 'æœ€åŽ', 'ä¸€æœŸ', 'å¥½', 'å‡‘ä¸ª', 'è„¸ç†Ÿ', 'ä»€ä¹ˆ', 'æ„æ€', 'å—¯', 'å¥½', 'æƒ…å†µ', 'äºŒè´§',\n",
    "     'ä»Šå¤©', 'æ•Œäºº', 'æœ‹å‹', 'è¿™é‡Œ', 'æ‰“', 'å¯èƒ½', 'å»¶è¿Ÿ', 'å‡ åˆ†é’Ÿ', 'å°½é‡', 'ä¿è¯', 'æ¯', 'ä¸€ä½', 'è¿™ä¸ª', 'æ—¶å€™', 'å‘µå‘µ', 'å‘µ', 'å¥½', 'å˜ž', 'æ©æ€¨', 'ä¸€ç¬‘', 'æ³¯', 'æ©ä»‡',\n",
    "     'å•¥', 'æƒ…å†µ', 'ä½ ä»¬', 'å“¦', 'å¥½', 'é¡¶æˆ˜', 'æ¸…äºº', '(', ')', 'åˆš', 'ä¸Šçº¿', 'æˆ‘ä»¬', 'åŠ æ²¹', 'æˆå‘˜', 'å…¨ä½“', 'é›†åˆ', 'æ°‘å¿ƒ', 'ä»»åŠ¡', 'å§', 'å“ª', 'è®¤è¯†', 'æ¸…æ¥š', 'ä¹ˆ', 'åˆ†é’Ÿ', 'æ‰“ä¸è¿‡', \n",
    "     'åˆ«', 'å‘€', 'æˆ˜åŠ›', 'ä»¥åŽ', 'å†å‡', 'ç•™ç‚¹', 'å…µ', 'åŽ»', 'æœ‰äºº', 'åœŸåŒª', 'æ¥ä¸ª', 'å¸®å¸®å¿™', 'ï¼š', 'ï¼‰', 'æœ‰äºº', 'ç¢°ç“·', 'åŽ‰å®³', 'å‘€', 'æ€Žä¹ˆ', 'ä¸ç†', 'å› ä¸º', 'è§‰å¾—', 'å’‹æ ·',\n",
    "      'æ…¢æ…¢', 'çŽ©å§', 'äº', 'å¤§å‘', 'åˆ«', 'äº’ç›¸', 'ä¼¤å®³', 'å‘Šè¯‰', 'æ‰“é‡Ž', 'æœ‰ç‚¹', 'è¿‡åˆ†', 'å›žå®¶', 'å…¬å‘Š', 'çœ‹', 'åŽ»', 'å°†', 'æˆ‘å¼€', 'ç›¸å¿˜', 'äºŽ', 'åˆ°', 'æ—è¾¹', 'ä¹', 'æœ‰ç¼˜åƒé‡Œ', 'ç›¸ä¼š',\n",
    "     'æœ‰ç¼˜', 'å„ä½', 'çœŸ', 'æ— èŠ', 'åˆ†é’Ÿ', 'æˆ‘æ¥', 'çœ‹çœ‹', 'æ', 'æ²¡æœ‰', 'ä¸€ä¸‹', 'ä¸€ä¸ª', 'ä¸Š', 'ä¸‹', 'ç”¨', 'ä¸è¦', 'ä½ç½®', 'è¿™ä¹ˆ', 'ç¹è£', 'è°', 'çŽ©', 'ç§’', 'æŠŠ', 'å¤šå°‘', 'å¤š', 'é­å›½',\n",
    "      'ä¸€äºŒä¸‰å››äº”', 'è¿‡æ¥', 'ä¹ç‚¹', 'é•¿å®‰', 'æ¬¡', 'ä¸æ˜¯', 'å¼€å§‹', 'é˜µå®¹', 'ä»¥ä¸Š', 'æ—¶é—´', 'å¾ˆ', 'æ¸…', 'å¸¦', 'åŸŽ', 'æ‰“é£ž', 'ä¼š', 'å’¯', 'åœ°ç‚¹', 'éƒ¡åŸŽ', 'ç•™å½±', 'æ´›é˜³', 'æƒ³', 'æœ‰æ²¡æœ‰', \n",
    "      'æž', 'ç¥', 'æå‰', 'éšä¾¿', 'çœ‹è§', 'ä¸ªäºº', 'èµ·æ¥', 'ä¸€ç‚®', 'ä¸è¡Œ', 'å«', 'å¯¹', 'è½ä½', 'ä¸Šè½¦', 'å¤©å¤©', 'ä¸å¥½', 'ä»¤', 'åˆ†', 'åŒº', 'é«˜', 'çŽ‹', 'å…¶ä»–', 'é€šå‘Š', 'å›´åŸŽ', 'è”ç›Ÿ',\n",
    "     'å¿«', 'å…µçº¿', 'åœ°æ–¹', 'å¤Ÿ', 'å’‹', 'çº¿', 'å°æ—¶', 'è·‘', 'åŽé¢', 'æ— ', 'èµ·', 'é‚£ä¸ª', 'èœ€', 'æ•£äºº', 'éƒ¡', 'æ‰€æœ‰äºº', 'æœ¬äºº', 'åŽŸå§‹', 'å¨±ä¹', 'èµ¶ç´§', 'ä¸€ç‚¹', 'cä½', 'é”™', 'å»ºç­‘',\n",
    "     'æˆéƒ½', 'ä¸€çŽ¯', 'å‡‘', 'å¸Œæœ›', 'æ’¤', 'é£žè¿‡åŽ»', 'é…åˆ', 'å…¶ä»–äºº', 'è¿‡', 'å‡ºå…µ', 'é‚£ä¹ˆ', 'éšæœº', 'æœ€å¥½', 'å…¨éƒ¨', 'æ‰', 'ä¸€ç›´', 'é¢†', 'ä¸­', ',', 'å¯', 'çŽ°', 'å¼€å¿ƒ', 'è·Ÿ', 'ä¸»å…¬',\n",
    "     'ç‚¸', 'é©¬ä¸Š', 'æœ¬æœ', 'ç…§', 'è¿‡èŠ‚', 'å¤§å°', 'æŠ¥ä»‡', 'ä¸‰å›½', 'ä»ŠåŽ', 'ä»¥å‰', 'æ¶ˆ', 'å¼Ÿå…„ä»¬', 'æ—©åˆ°', 'å·²ç»', 'è‡ªç«‹', 'åŸŽæ± ', 'å‡†æ—¶', 'ç§ç”°', 'æ˜¥èŠ‚', 'å·²æ”¾', 'ä¸‹ä½', 'å¤„',\n",
    "     'æ–¹å‘', 'å‚åŠ ', 'è¯¥', 'æµªè´¹', 'ç…§ç‰‡', 'ä¸–ç•Œ', 'è§', 'ä¸€æ¬¡', 'é›†ä½“', 'åšä¸ª', 'åˆ°ä½', 'å·®è·', 'å¤©', 'å°±ä½', 'æ‰“åŸŽ', 'æ²¡å‡ºæ¯', 'å¥‡æ€ª', 'å¥½åƒ', 'åŸå¤´', 'ä¸äº†', 'å“ªä¸ª', 'ä¸åˆ°', \n",
    "     'æ²¡å…µ', 'å½»åº•', 'æŠ¥', 'è®¸æ˜Œ', 'å“¥å“¥', 'åˆšåˆš', 'å†æ¥', 'åˆšæ‰', 'å›žæ¥', 'å¦‚æžœ', 'å‡ºæ¥', 'å‡ æ¬¡', 'æ€»æ˜¯', 'åº”è¯¥', 'å¥½å¤š', 'è¿‘', 'é•¿æ²™', 'ä¸€å…µ', 'ä¸æ¥', 'å¤ªè™š', 'éšæ„', 'åªæœ‰',\n",
    "     'ç­‰ä¼š', 'æ¡æ¸£ç§', 'æ­¤æ—¶æ­¤åˆ»', 'è¢«æŽ§', 'ç¬¬ä¸€', 'æ·±æ›´åŠå¤œ', 'å¹³æ°‘', 'éœ¸æœ', 'è„¸', 'æœ¬äº‹', 'æ‰“å‡º', 'åˆ«è¯´', 'æŽ§å·', 'æœ‰é’±', 'åˆ«äºº', 'è¢«æŽ§', 'æ®‹', 'ç‹—ä¸œè¥¿', \n",
    "      'åœ°å„¿', 'éš†å†¬', 'å¼º', 'å’šå’š', 'é”µ', 'æ•´ä¸ª', 'æŒ¨ä¸ª', 'ç¾¤', 'bb', 'ç¬”', 'å†…', 'é—´', 'å†…', 'ç•œç”Ÿ', 'å­—', 'å°å', 'ç«¥å­', 'å–œ', 'ç”·äºº', 'ç”·é£Ž', 'è€…', 'ä¸æ€•', 'py',\n",
    "     'ç‹—å¥´æ‰', 'å˜´ä¸Š', 'ç«‹äºº', 'è®¾æ—¶', 'è¿ž', 'å½“çœŸ', 'ä½†', 'ç»ä¸èµ·', 'ä»»ä½•', 'è€ƒéªŒ', 'å•ªå•ª', 'æ‰“è„¸', 'ä¸¤é¢ä¸‰åˆ€', 'å°äºº', 'æ™š', 'ç‚¹', 'è‡ªç”±', 'å¼€æ”¾', '1é˜Ÿ', 'å¹³å®‰', 'å–œä¹', 'æœˆ',\n",
    "     'è§£æ•£', 'éº»çƒ¦', 'éšè¿', 'ä¸œç€›', 'é¬¼å­', 'é‡Žç§', 'å…¨é£ž', 'ä¿æŒ', 'é˜Ÿå½¢', 'å¯’æ±Ÿ', 'å­¤å½±', 'ä½•å¿…', 'æ›¾', 'ç›¸è¯†', 'ç¡', 'æ™šå®‰', 'æ‰‹æœº', 'æ²¡ç”µ', '123', 'èŒ„å­', 'æ”¶å…µçº¿', 'å‡', \n",
    "      'è¿›æ­¥', 'å¾ˆå¤§', 'æ»¡çº§', 'é‡', 'å†ä¹Ÿ', 'ä¸æƒ³', 'æ¬ºè´Ÿ', 'å¼±å›¢', 'æ¬ºè´Ÿ', 'æœ¬å›½', 'å¼±å°', 'åˆ†æ‰‹', 'æ‰“æŽ‰', 'è¡Œ', 'æ•£ä¼™', 'è‡­è¡¨å­', 'ä¸€ç»„', 'è¿‡åŽ»', 'æŽ‰', 'å…¨ä¸€çŽ¯', 'æ ¼å­',\n",
    "     'æ ¡åœº', 'å‰¯', 'å†ä¹Ÿ', 'ä¸è§', 'å“', 'è·³', 'å‚»ç¬”', 'æ¯å¤©', 'æ—©ç‚¹', 'ä¼‘æ¯', 'ç§°å·', 'åºŸ', 'å…«å§“', 'å®¶å¥´', 'å‡ æŠŠ', 'æ¶æ˜¯', 'å‡ æŠŠ',\n",
    "     'èµ›å­£', 'æœå‰', 'ä¸€å¤©', 'ä¸€è·¯', 'æ¶ªé™µ', 'æœ‰ç©º', 'æŒ‰', 'é¡ºåº', 'æ•´ä½“', 'æŽ’åˆ—', 'ç‚¹ä¼š', 'å®‰æŽ’', 'å¤§æ®¿', 'ä¸å¸¦', 'åé˜²', 'å¥½å‹', 'å¾’å¼Ÿ', 'å°è½¦', 'æ­»å…‰å…‰',\n",
    "     'æ˜Žæ™š', 'é•¿å®‰åŸŽ', 'æœ¬åŒº', 'æä¾›', 'å…·ä½“åœ°å€', 'æ—¶å‘', 'åŸŽåˆ°', 'é“è¡€', 'å…·ä½“', 'åŠæ‰“', 'å½•å±', 'æ³¨æ„', 'æœ‰åˆ·', 'æš‚æ—¶', 'ç¦»å›¢', 'å—é—¨', 'å†›æ——', 'è´±ç‹—', 'çˆ½', 'ç‹—å¨˜å…»',\n",
    "    'è¥¿å—', 'é—¨', 'å†›æ——', 'å›´', 'ä¸‰çŽ¯', 'æŠ“ç´§', 'éª‘å…µ', 'è¿›æ”»',  'æŠ¢æ–°', 'ç‰ˆæœ¬', 'é¦–ç«™', 'å¤©çŽ‹', 'ç›–åœ°', 'è™Ž', 'å¤§ç™½', 'å–', 'è“è‰²', 'èœ€æ±‰', 'æ——', 'å¤§ç™½', 'å‘Š', 'å¦»',\n",
    "     'é“¶æ²³', 'å¥¥ç‰¹æ›¼', 'æ²™æ¯”', 'æ€»å–Š', 'çŽ›', 'æ²¡é’±åˆ«', 'æ¯”æ¯”', 'èƒ½è€', 'çº³', 'é—·', 'ä¸å¤š', 'é±¼å', 'å„è·¯', 'è‹±é›„', 'å›è´¼', 'æ‰“å®¶åŠ«èˆ', 'åŽŸ', 'åŒºä¸åˆ†', 'å›½ç±', 'æ‹ä¸ª',\n",
    "     'é’±å¤§ç‹—', 'æœŸå¾…', 'ä¸Ž', 'å†æ¬¡', 'ç›¸é‡', 'æœŸ', 'æˆªæ­¢', 'æƒ³æ¥', 'é£žè¡Œ', 'çŽ©è€', 'ä¸‡ä¸€', 'ä½Žæˆ˜å›¾']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw = list(set(sw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "829"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.extend(sw)\n",
    "len(stopwords)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def filter_sw(df):\n",
    "    \n",
    "    # return pd.Series([w for w in x if w not in stopwords])\n",
    "    \n",
    "    # for w in x:\n",
    "       # print(w, w not in stopwords)\n",
    "    # return [w for w in x if w not in stopwords]\n",
    "    \n",
    "    return df.apply(lambda l: [w for w in l if w not in stopwords])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_stopwords(texts):\n",
    "\n",
    "    texts['tokens'] = texts['tokens'].apply(lambda l: [w for w in l if w not in stopwords])\n",
    "    # texts['tokens'] = apply_parallel(texts['tokens'], lambda l: [w for w in l if w not in stopwords])\n",
    "    \n",
    "    # texts['tokens'] = apply_parallel(texts['tokens'], filter_sw)\n",
    "    # texts = texts.dropna()\n",
    "    \n",
    "    \n",
    "    # print(len(texts))\n",
    "    # texts.head(1)\n",
    "\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## repeats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_repeats(x):\n",
    "    \"\"\" tool\n",
    "    \"\"\"\n",
    "    # print(x)\n",
    "    \n",
    "    if 2 > len(x): return x\n",
    "    \n",
    "    if 2 == len(x): \n",
    "        return [x[0]] if x[0] == x[1] else x\n",
    "    \n",
    "    r = [x[i] for i in range(len(x)-2) if x[i] != x[i+1]]\n",
    "    if x[-1] == x[-2]:\n",
    "        r.append(x[-2])\n",
    "    else:\n",
    "        r.extend(x[-2:])\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_repeats(texts):\n",
    "\n",
    "    # è°¢è°¢, è°¢è°¢\n",
    "    # å–é…’, å–é…’\n",
    "\n",
    "    texts['tokens'] = texts['tokens'].apply(remove_repeats)\n",
    "    # print(len(texts))\n",
    "    # texts.head(1)\n",
    "\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'v' + num\n",
    "\n",
    "def is_v_num(x):\n",
    "    \"\"\" tool\n",
    "    \"\"\"\n",
    "    return 2 == len(x) and 'v' == x[0] and x[1].isnumeric()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_v_num(texts):\n",
    "\n",
    "    texts = texts[~texts['tokens'].apply(is_v_num)]\n",
    "    # print(len(texts))\n",
    "\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num + 'çº§'\n",
    "\n",
    "def is_num_ji(x):\n",
    "    \"\"\" tool\n",
    "    \"\"\"\n",
    "    return 2 == len(x) and x[0].isnumeric() and 'çº§' == x[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_num_ji(texts):\n",
    "\n",
    "    texts = texts[~texts['tokens'].apply(is_num_ji)]\n",
    "    # print(len(texts))\n",
    "\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_length(texts):\n",
    "    # texts['length'] = texts['tokens'].apply(len)\n",
    "    \n",
    "    texts = texts[texts['tokens'].apply(len) > 1]\n",
    "    # print(len(texts))\n",
    "    # print(texts.tail(10))\n",
    "\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# df = pd.DataFrame(texts)\n",
    "# df.head(1)\n",
    "texts.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(texts):\n",
    "\n",
    "    # df = df.astype(str).value_counts().reset_index().rename(columns={0:'cnt'})\n",
    "    # df.head(1)\n",
    "\n",
    "    texts['tokens'] = texts['tokens'].astype(str)\n",
    "    df = texts.groupby('tokens').agg({'tokens':['count'], 'content':[lambda x: pd.DataFrame.head(x,1)]}).reset_index()\n",
    "\n",
    "    df.columns = ['tokens', 'cnt', 'content']\n",
    "    df = df[['tokens','content', 'cnt']]\n",
    "    df = df.sort_values('cnt', ascending=False).reset_index(drop=True)\n",
    "    # df.head(1)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## freq more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq_more(df, n=None):\n",
    "\n",
    "    dfn = df[df['cnt'] >= n]\n",
    "    # print(dfn.shape)\n",
    "\n",
    "    return dfn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq_between(df, n1=None, n2=None):\n",
    "\n",
    "    dfn = df[(df['cnt'] >= n1) & (df['cnt'] < n2)]\n",
    "    # print(dfn.shape)\n",
    "\n",
    "    return dfn"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df5 = df[df['cnt'] >= 5]\n",
    "print(df5.shape)\n",
    "df5"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df4 = df[(df['cnt'] < 5) & (df['cnt'] >= 4)]\n",
    "print(df4.shape)\n",
    "df4"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df3 = df[(df['cnt'] < 4) & (df['cnt'] >= 3)]\n",
    "print(df3.shape)\n",
    "df3"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "counter = defaultdict(int)\n",
    "\n",
    "for tokens in df3.tokens:\n",
    "    for t in set(eval(tokens)):\n",
    "        counter[t] += 1\n",
    "        \n",
    "counter = sorted(counter.items(), key=lambda x: x[1], reverse=True)\n",
    "counter"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df2 = df[(df['cnt'] < 3) & (df['cnt'] >= 2)]\n",
    "print(df2.shape)\n",
    "df2"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dfn = df[df['cnt'] > 1]\n",
    "print(dfn.shape)\n",
    "# dfn"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df1 = df[df['cnt'] <= 1]\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: 2æœŸ æ ‡æ³¨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extracts(path, keep, filename):\n",
    "\n",
    "    try:\n",
    "        \n",
    "        texts = load(path, filename)\n",
    "        # texts = texts.head(10)\n",
    "\n",
    "        pipeline = [\n",
    "            filter_localization, \n",
    "            filter_battle,\n",
    "            filter_system_info,\n",
    "\n",
    "            clean_lower,\n",
    "            clean_special_words,\n",
    "            clean_numeric_only,\n",
    "            merge_chars,\n",
    "\n",
    "            tokenization,\n",
    "            split_cn,\n",
    "            split_special_words,\n",
    "            merge_words_3,\n",
    "            merge_words_2,\n",
    "            filter_stopwords,\n",
    "            filter_repeats,\n",
    "\n",
    "            filter_v_num,\n",
    "            filter_num_ji,\n",
    "            filter_length,\n",
    "                   ]\n",
    "\n",
    "        for f in pipeline:\n",
    "            # print(f)\n",
    "            t0 = time.time()\n",
    "            texts = f(texts)\n",
    "            # print(time.time()-t0)\n",
    "\n",
    "        df = extract(texts)\n",
    "        # print(df.shape)\n",
    "\n",
    "        # dfn = freq_more(df, 5)\n",
    "        # dfn = freq_between(df, 3, 5)\n",
    "        # dfn = freq_more(df, 2)\n",
    "        # dfn = freq_between(df, 1, 2)\n",
    "        dfn = keep(df)\n",
    "        print(dfn.shape)\n",
    "        # print()\n",
    "\n",
    "        return dfn\n",
    "    \n",
    "    except:\n",
    "        print(filename)\n",
    "        traceback.print_exc()\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = '/home/wangyh/data/yk-sgz2017-chat/data-2-20201223'\n",
    "# filename = '2020_09_25.csv'\n",
    "# filename = '2020_09_24.csv'\n",
    "# filename = '2020_08_20.csv'\n",
    "\n",
    "path = '/home/wangyh/data/yk-sgz2017-chat/data-7-20210120'"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%time extracts(path, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_similarity(s1, s2):\n",
    "    _s1 = set(s1)\n",
    "    _s2 = set(s2)\n",
    "    return len(_s1 & _s2) / max(len(_s1), len(_s2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def in_similarity(s1, s):\n",
    "    for _ in s1:\n",
    "        # if abs(len(_)-len(c)) < 3 and edit_distance.SequenceMatcher(_, c).ratio() > 0.9:\n",
    "        if abs(len(_)-len(s)) < 3 and set_similarity(_,s) > 0.9:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get(keep, num=None):\n",
    "\n",
    "    # split\n",
    "    # print(len(os.listdir(path)))\n",
    "    t0 = time.time()\n",
    "    with Pool(8) as p:\n",
    "        tasks = os.listdir(path)\n",
    "        \n",
    "        # dfs = p.map(partial(extracts, path, keep), tasks)\n",
    "        \n",
    "        dfs = []\n",
    "        for _ in tqdm(p.imap(\n",
    "            partial(extracts, path, keep), \n",
    "            tasks\n",
    "        ), total=len(tasks)):\n",
    "            dfs.append(_)\n",
    "        \n",
    "    p.join()\n",
    "    print(time.time() - t0)\n",
    "\n",
    "    # count\n",
    "    df_final = pd.concat(dfs).reset_index(drop=True)\n",
    "    print(df_final.shape)\n",
    "\n",
    "    df_ = df_final.drop(columns=['cnt'])\n",
    "    df_ = df_.drop_duplicates('tokens')\n",
    "\n",
    "    print(df_.shape)\n",
    "\n",
    "    if num is not None: df_ = df_.head(num)\n",
    "\n",
    "    # drop duplicates\n",
    "        \n",
    "    r = defaultdict(list)\n",
    "    r[0] = []\n",
    "\n",
    "    for c in tqdm(df_.content.to_list()):\n",
    "        flag = True # not exist\n",
    "\n",
    "        for i in range(max(0,len(c)-3), min(max(r.keys()),len(c)+3)):\n",
    "            if in_similarity(r[i], c):\n",
    "                flag = False\n",
    "                break\n",
    "                \n",
    "        if flag:\n",
    "            r[len(c)].append(c)\n",
    "\n",
    "    r = list(chain.from_iterable(r.values()))\n",
    "    print(len(r))\n",
    "\n",
    "    return pd.DataFrame({'text': r})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/107 [00:00<?, ?it/s]Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Building prefix dict from the default dictionary ...\n",
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 1.252 seconds.\n",
      "Prefix dict has been built successfully.\n",
      "Loading model cost 1.259 seconds.\n",
      "Prefix dict has been built successfully.\n",
      "Loading model cost 1.247 seconds.\n",
      "Prefix dict has been built successfully.\n",
      "Loading model cost 1.233 seconds.\n",
      "Prefix dict has been built successfully.\n",
      "Loading model cost 1.248 seconds.\n",
      "Prefix dict has been built successfully.\n",
      "Loading model cost 1.267 seconds.\n",
      "Prefix dict has been built successfully.\n",
      "Loading model cost 1.278 seconds.\n",
      "Prefix dict has been built successfully.\n",
      "Loading model cost 1.242 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(71, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 1/107 [00:04<07:09,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(71, 3)\n",
      "(105, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|â–         | 2/107 [00:05<05:30,  3.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(117, 3)\n",
      "(159, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|â–Ž         | 3/107 [00:06<04:34,  2.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(145, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|â–         | 5/107 [00:06<03:12,  1.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(84, 3)\n",
      "(85, 3)\n",
      "(197, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|â–‹         | 7/107 [00:08<02:30,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(94, 3)\n",
      "(153, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|â–‹         | 8/107 [00:10<02:47,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(126, 3)\n",
      "(122, 3)\n",
      "(144, 3)\n",
      "(171, 3)\n",
      "(70, 3)\n",
      "(95, 3)\n",
      "(363, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|â–ˆ         | 11/107 [00:13<02:28,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(186, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|â–ˆâ–Œ        | 17/107 [00:14<01:40,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(71, 3)\n",
      "(140, 3)\n",
      "(140, 3)\n",
      "(308, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|â–ˆâ–Š        | 20/107 [00:20<01:58,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(185, 3)\n",
      "(212, 3)\n",
      "(284, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|â–ˆâ–ˆâ–       | 24/107 [00:21<01:30,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(231, 3)\n",
      "(126, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|â–ˆâ–ˆâ–Ž       | 25/107 [00:24<02:08,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(101, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|â–ˆâ–ˆâ–‹       | 29/107 [00:24<01:27,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(132, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|â–ˆâ–ˆâ–Š       | 30/107 [00:25<01:11,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(208, 3)\n",
      "(45, 3)\n",
      "(166, 3)\n",
      "(108, 3)\n",
      "(134, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|â–ˆâ–ˆâ–‰       | 31/107 [00:27<01:30,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(145, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|â–ˆâ–ˆâ–ˆ       | 33/107 [00:28<01:20,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(104, 3)\n",
      "(124, 3)\n",
      "(136, 3)\n",
      "(146, 3)\n",
      "(219, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 36/107 [00:33<01:23,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(204, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|â–ˆâ–ˆâ–ˆâ–‹      | 39/107 [00:34<01:04,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(183, 3)\n",
      "(108, 3)\n",
      "(113, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 44/107 [00:36<00:48,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(122, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 46/107 [00:37<00:46,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(162, 3)\n",
      "(68, 3)\n",
      "(178, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 47/107 [00:38<00:48,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(119, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 48/107 [00:38<00:40,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(118, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 50/107 [00:40<00:38,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(97, 3)\n",
      "(120, 3)\n",
      "(84, 3)\n",
      "(113, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 52/107 [00:43<00:54,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(105, 3)\n",
      "(115, 3)\n",
      "(156, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 54/107 [00:44<00:45,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(153, 3)\n",
      "(120, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 59/107 [00:46<00:35,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(145, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 61/107 [00:48<00:30,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(112, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 62/107 [00:48<00:32,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(121, 3)\n",
      "(118, 3)\n",
      "(112, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 63/107 [00:49<00:24,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(111, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 66/107 [00:50<00:23,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(163, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 67/107 [00:51<00:27,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(143, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 68/107 [00:53<00:33,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(155, 3)\n",
      "(97, 3)\n",
      "(118, 3)\n",
      "(142, 3)\n",
      "(147, 3)\n",
      "(107, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 69/107 [00:58<01:28,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 75/107 [00:59<00:52,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(136, 3)\n",
      "(131, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 76/107 [01:00<00:48,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(164, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 78/107 [01:03<00:46,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(135, 3)\n",
      "(134, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 79/107 [01:07<01:01,  2.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(121, 3)\n",
      "(102, 3)\n",
      "(186, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 80/107 [01:09<00:57,  2.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(111, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 83/107 [01:09<00:36,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(58, 3)\n",
      "(104, 3)\n",
      "(118, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 85/107 [01:12<00:33,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(125, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 87/107 [01:14<00:26,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(82, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 88/107 [01:15<00:20,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(124, 3)\n",
      "(87, 3)\n",
      "(96, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 89/107 [01:17<00:28,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(182, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 92/107 [01:18<00:16,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(115, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 93/107 [01:21<00:24,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(108, 3)\n",
      "(145, 3)\n",
      "(94, 3)\n",
      "(91, 3)\n",
      "(162, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 94/107 [01:24<00:27,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(163, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 99/107 [01:27<00:13,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(146, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 101/107 [01:28<00:07,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49, 3)\n",
      "(108, 3)\n",
      "(120, 3)\n",
      "(165, 3)\n",
      "(168, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 102/107 [01:31<00:09,  1.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(206, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 107/107 [01:32<00:00,  1.15it/s]\n",
      "  6%|â–Œ         | 537/9169 [00:00<00:01, 5348.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92.94110298156738\n",
      "(14347, 3)\n",
      "(9169, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9169/9169 [00:26<00:00, 344.07it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8989\n",
      "(8989, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ä¸ºäº†å†›å›¢æ›´å¥½åœ°å‘å±•ï¼Œèµ„æºæ›´å¥½åœ°åˆ©ç”¨ï¼Œå¤§å®¶ä¸€èµ·ä½œæˆ˜ï¼Œå…„å¼ŸåŠ å¾®ä¿¡ï¼šsvip12126ï¼Œç»„ç»‡æ‰“åŸŽï¼Œå†›å›¢ç¾¤é‡Œæœ‰æ”»ç•¥å’Œå†…æµ‹è€äººå¸¦é˜Ÿï¼Œå°±å·®ä½ ä¸€ä¸ªäººæ²¡åŠ äº†ï¼Œæ²¡åŠ çš„å½“æœºå™¨äººè¸¢äº†</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ä¸ºäº†å†›å›¢çš„å‘å±•å’Œæ”»åŸŽï¼Œå¤§å®¶åŠ ä¸‹å†›å›¢é•¿å¾®ä¿¡ï¼š4664632æ¥å†›å›¢ç¾¤è®¨è®ºäº¤æµï¼Œæœ‰é˜µå®¹æ”»åŸŽæ”»ç•¥ï¼Œå’Œå¯¹æ¢ç ï¼Œä¸€èµ·ä½œæˆ˜ï¼Œè€äººå¸¦é˜Ÿï¼Œä¸€èµ·å‘å±•ï¼Œä»¥åŽå†›å›¢æˆ˜ï¼Œæ²¡åŠ çš„å½“æœºå™¨äººè¸¢äº†</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ä¸ºäº†å†›å›¢æ›´å¥½çš„å‘å±•ï¼Œèµ„æºæ›´å¥½çš„åˆ©ç”¨ï¼Œå¤§å®¶ä¸€èµ·ä½œæˆ˜ï¼Œå…„å¼ŸåŠ å†›å›¢é•¿å¾®ä¿¡ï¼šsvip12126ï¼Œé¢†ç¤¼åŒ…ï¼Œç¾¤é‡Œæœ‰æ”»ç•¥å’Œå†…æµ‹è€äººå¸¦é˜Ÿï¼Œå°±å·®ä½ ä¸€ä¸ªäººæ²¡åŠ ï¼Œæ²¡åŠ çš„å½“æœºå™¨äººæ¸…ç†äº†</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                               text\n",
       "0  ä¸ºäº†å†›å›¢æ›´å¥½åœ°å‘å±•ï¼Œèµ„æºæ›´å¥½åœ°åˆ©ç”¨ï¼Œå¤§å®¶ä¸€èµ·ä½œæˆ˜ï¼Œå…„å¼ŸåŠ å¾®ä¿¡ï¼šsvip12126ï¼Œç»„ç»‡æ‰“åŸŽï¼Œå†›å›¢ç¾¤é‡Œæœ‰æ”»ç•¥å’Œå†…æµ‹è€äººå¸¦é˜Ÿï¼Œå°±å·®ä½ ä¸€ä¸ªäººæ²¡åŠ äº†ï¼Œæ²¡åŠ çš„å½“æœºå™¨äººè¸¢äº†\n",
       "1  ä¸ºäº†å†›å›¢çš„å‘å±•å’Œæ”»åŸŽï¼Œå¤§å®¶åŠ ä¸‹å†›å›¢é•¿å¾®ä¿¡ï¼š4664632æ¥å†›å›¢ç¾¤è®¨è®ºäº¤æµï¼Œæœ‰é˜µå®¹æ”»åŸŽæ”»ç•¥ï¼Œå’Œå¯¹æ¢ç ï¼Œä¸€èµ·ä½œæˆ˜ï¼Œè€äººå¸¦é˜Ÿï¼Œä¸€èµ·å‘å±•ï¼Œä»¥åŽå†›å›¢æˆ˜ï¼Œæ²¡åŠ çš„å½“æœºå™¨äººè¸¢äº†\n",
       "2  ä¸ºäº†å†›å›¢æ›´å¥½çš„å‘å±•ï¼Œèµ„æºæ›´å¥½çš„åˆ©ç”¨ï¼Œå¤§å®¶ä¸€èµ·ä½œæˆ˜ï¼Œå…„å¼ŸåŠ å†›å›¢é•¿å¾®ä¿¡ï¼šsvip12126ï¼Œé¢†ç¤¼åŒ…ï¼Œç¾¤é‡Œæœ‰æ”»ç•¥å’Œå†…æµ‹è€äººå¸¦é˜Ÿï¼Œå°±å·®ä½ ä¸€ä¸ªäººæ²¡åŠ ï¼Œæ²¡åŠ çš„å½“æœºå™¨äººæ¸…ç†äº†"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = get(partial(freq_more, n=2))\n",
    "print(df1.shape)\n",
    "df1.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/107 [00:00<?, ?it/s]Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 1.275 seconds.\n",
      "Prefix dict has been built successfully.\n",
      "Loading model cost 1.265 seconds.\n",
      "Prefix dict has been built successfully.\n",
      "Loading model cost 1.269 seconds.\n",
      "Prefix dict has been built successfully.\n",
      "Loading model cost 1.236 seconds.\n",
      "Prefix dict has been built successfully.\n",
      "Loading model cost 1.246 seconds.\n",
      "Prefix dict has been built successfully.\n",
      "Loading model cost 1.241 seconds.\n",
      "Prefix dict has been built successfully.\n",
      "Loading model cost 1.233 seconds.\n",
      "Prefix dict has been built successfully.\n",
      "Loading model cost 1.225 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3745, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 1/107 [00:04<07:08,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3239, 3)\n",
      "(4221, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|â–         | 2/107 [00:04<05:27,  3.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8327, 3)\n",
      "(8700, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|â–Ž         | 3/107 [00:06<04:34,  2.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8401, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|â–         | 5/107 [00:06<03:10,  1.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3959, 3)\n",
      "(10557, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|â–‹         | 7/107 [00:07<02:29,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4626, 3)\n",
      "(4462, 3)\n",
      "(9037, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|â–‹         | 8/107 [00:10<02:52,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8028, 3)\n",
      "(8278, 3)\n",
      "(6058, 3)\n",
      "(5412, 3)\n",
      "(9139, 3)\n",
      "(13240, 3)(4543, 3)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|â–ˆ         | 11/107 [00:13<02:32,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10212, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|â–ˆâ–Œ        | 17/107 [00:14<01:41,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4509, 3)\n",
      "(8752, 3)\n",
      "(7593, 3)\n",
      "(13749, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|â–ˆâ–Š        | 20/107 [00:20<02:02,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10159, 3)\n",
      "(10153, 3)\n",
      "(11799, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|â–ˆâ–ˆâ–       | 24/107 [00:22<01:33,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7215, 3)\n",
      "(5583, 3)\n",
      "(5538, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|â–ˆâ–ˆâ–Ž       | 25/107 [00:25<02:18,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8167, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|â–ˆâ–ˆâ–Š       | 30/107 [00:25<01:33,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10105, 3)\n",
      "(5165, 3)\n",
      "(8318, 3)\n",
      "(2947, 3)\n",
      "(7982, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|â–ˆâ–ˆâ–‰       | 31/107 [00:27<01:46,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9566, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|â–ˆâ–ˆâ–ˆ       | 33/107 [00:29<01:27,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5776, 3)\n",
      "(6489, 3)\n",
      "(6416, 3)\n",
      "(5481, 3)\n",
      "(10712, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 36/107 [00:33<01:31,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6607, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|â–ˆâ–ˆâ–ˆâ–‹      | 39/107 [00:34<01:05,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10702, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 39%|â–ˆâ–ˆâ–ˆâ–‰      | 42/107 [00:34<00:48,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5999, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 44/107 [00:36<00:45,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5369, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 45/107 [00:36<00:37,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5620, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 46/107 [00:37<00:47,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6280, 3)\n",
      "(6683, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 47/107 [00:38<00:51,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4505, 3)\n",
      "(6194, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 48/107 [00:39<00:46,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6020, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 50/107 [00:40<00:38,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5284, 3)\n",
      "(6017, 3)\n",
      "(6100, 3)\n",
      "(5820, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 52/107 [00:44<00:57,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6146, 3)\n",
      "(6104, 3)\n",
      "(6102, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 54/107 [00:45<00:46,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5895, 3)\n",
      "(5869, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 59/107 [00:47<00:35,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5345, 3)\n",
      "(6595, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 61/107 [00:48<00:36,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5814, 3)\n",
      "(6059, 3)\n",
      "(5477, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 62/107 [00:49<00:36,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7197, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 66/107 [00:51<00:27,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6478, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 67/107 [00:52<00:28,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5555, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 68/107 [00:53<00:32,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5952, 3)\n",
      "(6605, 3)\n",
      "(5581, 3)\n",
      "(7595, 3)\n",
      "(6894, 3)\n",
      "(4008, 3)\n",
      "(5767, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 69/107 [00:59<01:38,  2.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4226, 3)\n",
      "(7395, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 76/107 [01:00<00:56,  1.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7154, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 78/107 [01:05<00:57,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6292, 3)\n",
      "(7056, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 79/107 [01:07<01:01,  2.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5077, 3)\n",
      "(6507, 3)\n",
      "(7318, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 80/107 [01:10<01:00,  2.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5601, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 83/107 [01:10<00:38,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3025, 3)\n",
      "(6179, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 85/107 [01:12<00:32,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6662, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 86/107 [01:13<00:25,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4693, 3)\n",
      "(7803, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 87/107 [01:15<00:29,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6304, 3)\n",
      "(3279, 3)\n",
      "(6314, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 89/107 [01:18<00:25,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6071, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 92/107 [01:18<00:15,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6040, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 93/107 [01:22<00:24,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4946, 3)\n",
      "(5288, 3)\n",
      "(6513, 3)\n",
      "(7470, 3)\n",
      "(8033, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 94/107 [01:24<00:26,  2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6986, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 99/107 [01:28<00:13,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6326, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 101/107 [01:28<00:07,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2576, 3)\n",
      "(6722, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 102/107 [01:31<00:08,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7573, 3)\n",
      "(6572, 3)\n",
      "(5643, 3)\n",
      "(8719, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 107/107 [01:33<00:00,  1.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94.10532808303833\n",
      "(710959, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|â–         | 565/40000 [00:00<00:06, 5638.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(647702, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40000/40000 [08:40<00:00, 76.89it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39891\n",
      "(39891, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ä½ æ²¡ä¸Šå…µå™¨</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>æ²¡ä¸Šè¿‡å­¦ï¼Ÿ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>æˆ‘æ²¡è¡¥æ»¡å…µ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    text\n",
       "0  ä½ æ²¡ä¸Šå…µå™¨\n",
       "1  æ²¡ä¸Šè¿‡å­¦ï¼Ÿ\n",
       "2  æˆ‘æ²¡è¡¥æ»¡å…µ"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = get(partial(freq_between, n1=1, n2=2), num=int(4e4))\n",
    "print(df2.shape)\n",
    "df2.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39779, 1)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df2[df2.text.apply(lambda x: not in_similarity(df1.text.to_list(), x))]\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['version'] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv('./data/dataset_ads-20210420-2.csv', encoding='utf8', index=False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!pip -q install edit_distance"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import edit_distance\n",
    "\n",
    "ref = [1, 2, 3, 4]\n",
    "hyp = [1, 2, 4, 5, 6]\n",
    "\n",
    "sm = edit_distance.SequenceMatcher(a=ref, b=hyp)\n",
    "print(sm.get_opcodes())\n",
    "print(sm.ratio())\n",
    "print(sm.get_matching_blocks())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "set('123') & set('423')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "set_similarity('123', '234')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# df_.to_excel('./data/dataset_ads-20210113-1.xlsx', encoding='utf8', index=False)\n",
    "# df_.to_excel('./data/dataset_ads-20210120-1.xlsx', encoding='utf8', index=False)\n",
    "\n",
    "# df_.to_excel('./data/dataset_ads-20210201-1.xlsx', encoding='utf8', index=False)\n",
    "# df_.to_excel('./data/dataset_ads-20210201-2.xlsx', encoding='utf8', index=False)\n",
    "\n",
    "# df_.to_excel('./data/dataset_ads-20210420-1.xlsx', encoding='utf8', index=False)\n",
    "df_.to_excel('./data/dataset_ads-20210420-2.xlsx', encoding='utf8', index=False)\n",
    "\n",
    "print(df_.shape)\n",
    "df_.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
